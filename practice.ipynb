{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e833ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "     -------------------------------------- 394.2/394.2 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from azure-storage-blob) (4.3.0)\n",
      "Collecting isodate>=0.6.1\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.7/41.7 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0,>=1.28.0\n",
      "  Downloading azure_core-1.29.5-py3-none-any.whl (192 kB)\n",
      "     ------------------------------------- 192.4/192.4 kB 11.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from azure-storage-blob) (37.0.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.28.1)\n",
      "Collecting typing-extensions>=4.3.0\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\khand\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2022.9.14)\n",
      "Installing collected packages: typing-extensions, isodate, azure-core, azure-storage-blob\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed azure-core-1.29.5 azure-storage-blob-12.19.0 isodate-0.6.1 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9306ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to Azure Storage Blob: journeydata/january_yellow_taxidata.parquet\n",
      "File uploaded to Azure Storage Blob: journeydata/january_green_taxidata.parquet\n",
      "File uploaded to Azure Storage Blob: journeydata/feburary_yellow_taxidata.parquet\n",
      "File uploaded to Azure Storage Blob: journeydata/feburary_green_taxidata.parquet\n",
      "File uploaded to Azure Storage Blob: journeydata/march_yellow_taxidata.parquet\n",
      "File uploaded to Azure Storage Blob: journeydata/march_green_taxidata.parquet\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "\n",
    "# Azure Storage Account details\n",
    "account_name = 'journeygroup'\n",
    "account_key = '2MVcmcztJuQBAB2QkioYpHDfWwQbYgMK4dCxpM59RKa2nUU4TtMs7eoDSymhiSbYdc9aBoFAoqhW+ASte7GP7g=='\n",
    "container_name = 'journeydata'\n",
    "\n",
    "# Function to upload Parquet file to Azure Storage Blob\n",
    "def upload_parquet_to_blob(parquet_url, blob_name):\n",
    "    # Download the Parquet file content\n",
    "    response = requests.get(parquet_url)\n",
    "    parquet_file_content = response.content\n",
    "\n",
    "    # Create a connection to Azure Storage Blob\n",
    "    blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    # Upload the Parquet file to Azure Storage Blob\n",
    "    blob_client.upload_blob(parquet_file_content, overwrite=True)\n",
    "\n",
    "    print(f\"File uploaded to Azure Storage Blob: {blob_name}\")\n",
    "\n",
    "# Example: Upload the yellow_tripdata_2023-01.parquet file\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet', 'journeydata/january_yellow_taxidata.parquet')\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet', 'journeydata/january_green_taxidata.parquet')\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet', 'journeydata/feburary_yellow_taxidata.parquet')\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet', 'journeydata/feburary_green_taxidata.parquet')\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet', 'journeydata/march_yellow_taxidata.parquet')\n",
    "upload_parquet_to_blob('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet', 'journeydata/march_green_taxidata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48f66ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_yellow_taxidata.parquet\n",
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_yellow_taxidata.parquet\n",
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_yellow_taxidata.parquet\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "# Azure Storage Account details\n",
    "account_name = 'journeygroup'\n",
    "account_key = '2MVcmcztJuQBAB2QkioYpHDfWwQbYgMK4dCxpM59RKa2nUU4TtMs7eoDSymhiSbYdc9aBoFAoqhW+ASte7GP7g=='\n",
    "container_name = 'journeydata'\n",
    "\n",
    "# Function to download Parquet file from Azure Storage Blob\n",
    "def download_parquet_from_blob(blob_name, local_file_path):\n",
    "    # Create a connection to Azure Storage Blob\n",
    "    blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    # Download the blob content\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_content = blob_data.readall()\n",
    "\n",
    "    # Write the blob content to a local file\n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(blob_content)\n",
    "\n",
    "    print(f\"File downloaded to: {local_file_path}\")\n",
    "\n",
    "# Example: Download the january_yellow_taxidata.parquet file\n",
    "download_parquet_from_blob('journeydata/january_yellow_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_yellow_taxidata.parquet')\n",
    "download_parquet_from_blob('journeydata/feburary_yellow_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_yellow_taxidata.parquet')\n",
    "download_parquet_from_blob('journeydata/march_yellow_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_yellow_taxidata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cffde610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_green_taxidata.parquet\n",
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_green_taxidata.parquet\n",
      "File downloaded to: C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_green_taxidata.parquet\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "# Azure Storage Account details\n",
    "account_name = 'journeygroup'\n",
    "account_key = '2MVcmcztJuQBAB2QkioYpHDfWwQbYgMK4dCxpM59RKa2nUU4TtMs7eoDSymhiSbYdc9aBoFAoqhW+ASte7GP7g=='\n",
    "container_name = 'journeydata'\n",
    "\n",
    "# Function to download Parquet file from Azure Storage Blob\n",
    "def download_parquet_from_blob(blob_name, local_file_path):\n",
    "    # Create a connection to Azure Storage Blob\n",
    "    blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    # Download the blob content\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_content = blob_data.readall()\n",
    "\n",
    "    # Write the blob content to a local file\n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(blob_content)\n",
    "\n",
    "    print(f\"File downloaded to: {local_file_path}\")\n",
    "\n",
    "# Example: Download the january_yellow_taxidata.parquet file\n",
    "download_parquet_from_blob('journeydata/january_green_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_green_taxidata.parquet')\n",
    "download_parquet_from_blob('journeydata/feburary_green_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_green_taxidata.parquet')\n",
    "download_parquet_from_blob('journeydata/march_green_taxidata.parquet', r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_green_taxidata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c155c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tpep_pickup_datetime  PULocationID  total_amount Taxi_Color    Borough  \\\n",
      "0  2023-01-01 00:32:10           161         14.30     Yellow  Manhattan   \n",
      "1  2023-01-01 00:55:08            43         16.90     Yellow  Manhattan   \n",
      "2  2023-01-01 00:25:04            48         34.90     Yellow  Manhattan   \n",
      "3  2023-01-01 00:03:48           138         20.85     Yellow     Queens   \n",
      "4  2023-01-01 00:10:29           107         19.68     Yellow  Manhattan   \n",
      "5  2023-01-01 00:50:34           161         27.80     Yellow  Manhattan   \n",
      "6  2023-01-01 00:09:22           239         20.52     Yellow  Manhattan   \n",
      "7  2023-01-01 00:27:12           142         64.44     Yellow  Manhattan   \n",
      "8  2023-01-01 00:21:44           164         28.38     Yellow  Manhattan   \n",
      "9  2023-01-01 00:39:42           141         19.90     Yellow  Manhattan   \n",
      "\n",
      "                    Zone  \n",
      "0         Midtown Center  \n",
      "1           Central Park  \n",
      "2           Clinton East  \n",
      "3      LaGuardia Airport  \n",
      "4               Gramercy  \n",
      "5         Midtown Center  \n",
      "6  Upper West Side South  \n",
      "7    Lincoln Square East  \n",
      "8          Midtown South  \n",
      "9        Lenox Hill West  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_location = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\ID_Data.xlsx'\n",
    "location_info_df = pd.read_excel(file_path_location)\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "file_path = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_yellow_taxidata.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "feb_file_path = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_yellow_taxidata.parquet'\n",
    "df_feb = pd.read_parquet(feb_file_path)\n",
    "\n",
    "march_file_path = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_yellow_taxidata.parquet'\n",
    "df_march = pd.read_parquet(march_file_path)\n",
    "\n",
    "# Specify the columns to be removed\n",
    "columns_to_remove = [\n",
    "    'payment_type',\n",
    "    'fare_amount',\n",
    "    'extra',\n",
    "    'mta_tax',\n",
    "    'tip_amount',\n",
    "    'tolls_amount',\n",
    "    'improvement_surcharge',\n",
    "    'congestion_surcharge',\n",
    "    'airport_fee',\n",
    "    'passenger_count',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'trip_distance',\n",
    "    'RatecodeID',\n",
    "    'store_and_fwd_flag',\n",
    "    'VendorID',\n",
    "    'DOLocationID'\n",
    "]\n",
    "\n",
    "# Drop the specified columns if they exist\n",
    "for col in columns_to_remove:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=col)\n",
    "    if col in df_feb.columns:\n",
    "        df_feb = df_feb.drop(columns=col)\n",
    "    if col in df_march.columns:\n",
    "        df_march = df_march.drop(columns=col)\n",
    "\n",
    "# Concatenate DataFrames vertically\n",
    "df = pd.concat([df, df_feb, df_march], ignore_index=True)\n",
    "\n",
    "# Add a new column 'Taxi_Color' with each cell filled with 'Yellow'\n",
    "df['Taxi_Color'] = 'Yellow'\n",
    "\n",
    "# Merge the main DataFrame with the location information DataFrame\n",
    "df = pd.merge(df, location_info_df, left_on='PULocationID', right_on='LocationID', how='left')\n",
    "\n",
    "# Drop the redundant 'LocationID' column\n",
    "df = df.drop(columns=['LocationID'])\n",
    "df = df.drop(columns=['Airport_fee'])\n",
    "df = df.drop(columns=['service_zone'])\n",
    "# Now 'df' contains the data with the specified columns removed and a new 'Taxi_Color' column\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cf27f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lpep_pickup_datetime  PULocationID  total_amount Taxi_Color    Borough  \\\n",
      "0  2023-01-01 00:26:10           166         24.18      Green  Manhattan   \n",
      "1  2023-01-01 00:51:03            24         15.84      Green  Manhattan   \n",
      "2  2023-01-01 00:35:12           223         11.64      Green     Queens   \n",
      "3  2023-01-01 00:13:14            41         10.20      Green  Manhattan   \n",
      "4  2023-01-01 00:33:04            41          8.00      Green  Manhattan   \n",
      "5  2023-01-01 00:53:31            41         22.95      Green  Manhattan   \n",
      "6  2023-01-01 00:09:14           181         29.20      Green   Brooklyn   \n",
      "7  2023-01-01 00:11:58            24         16.70      Green  Manhattan   \n",
      "8  2023-01-01 00:41:29            41         10.70      Green  Manhattan   \n",
      "9  2023-01-01 00:50:32            24         32.95      Green  Manhattan   \n",
      "\n",
      "                  Zone service_zone  \n",
      "0  Morningside Heights    Boro Zone  \n",
      "1         Bloomingdale  Yellow Zone  \n",
      "2             Steinway    Boro Zone  \n",
      "3       Central Harlem    Boro Zone  \n",
      "4       Central Harlem    Boro Zone  \n",
      "5       Central Harlem    Boro Zone  \n",
      "6           Park Slope    Boro Zone  \n",
      "7         Bloomingdale  Yellow Zone  \n",
      "8       Central Harlem    Boro Zone  \n",
      "9         Bloomingdale  Yellow Zone  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_location = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\ID_Data.xlsx'\n",
    "location_info_df = pd.read_excel(file_path_location)\n",
    "\n",
    "# Read the Parquet files into DataFrames\n",
    "file_path_jan = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\january_green_taxidata.parquet'\n",
    "file_path_feb = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\feburary_green_taxidata.parquet'\n",
    "file_path_march = r'C:\\Users\\khand\\OneDrive\\Desktop\\STA 3000\\march_green_taxidata.parquet'\n",
    "\n",
    "df_jan = pd.read_parquet(file_path_jan)\n",
    "df_feb = pd.read_parquet(file_path_feb)\n",
    "df_march = pd.read_parquet(file_path_march)\n",
    "\n",
    "# Concatenate DataFrames vertically\n",
    "df_green = pd.concat([df_jan, df_feb, df_march], ignore_index=True)\n",
    "\n",
    "# Specify the columns to be removed\n",
    "columns_to_remove = [\n",
    "    'payment_type',\n",
    "    'fare_amount',\n",
    "    'extra',\n",
    "    'mta_tax',\n",
    "    'tip_amount',\n",
    "    'tolls_amount',\n",
    "    'improvement_surcharge',\n",
    "    'congestion_surcharge',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'RatecodeID',\n",
    "    'store_and_fwd_flag',\n",
    "    'VendorID',\n",
    "    'DOLocationID',\n",
    "    'lpep_dropoff_datetime',\n",
    "    'ehail_fee',\n",
    "    'trip_type'\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df_green = df_green.drop(columns=columns_to_remove)\n",
    "\n",
    "# Add a new column 'Taxi_Color' with each cell filled with 'Green'\n",
    "df_green['Taxi_Color'] = 'Green'\n",
    "\n",
    "# Merge the DataFrame with the location information DataFrame\n",
    "df_green = pd.merge(df_green, location_info_df, left_on='PULocationID', right_on='LocationID', how='left')\n",
    "\n",
    "# Drop the redundant 'LocationID' column\n",
    "df_green = df_green.drop(columns=['LocationID'])\n",
    "\n",
    "# Now 'df_green' contains the data with the specified columns removed and a new 'Taxi_Color' column\n",
    "print(df_green.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dc5ae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>Taxi_Color</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:26:10</td>\n",
       "      <td>166</td>\n",
       "      <td>24.18</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Morningside Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:51:03</td>\n",
       "      <td>24</td>\n",
       "      <td>15.84</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Bloomingdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:35:12</td>\n",
       "      <td>223</td>\n",
       "      <td>11.64</td>\n",
       "      <td>Green</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Steinway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:13:14</td>\n",
       "      <td>41</td>\n",
       "      <td>10.20</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Central Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:33:04</td>\n",
       "      <td>41</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Central Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-01 00:53:31</td>\n",
       "      <td>41</td>\n",
       "      <td>22.95</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Central Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-01 00:09:14</td>\n",
       "      <td>181</td>\n",
       "      <td>29.20</td>\n",
       "      <td>Green</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Park Slope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-01 00:11:58</td>\n",
       "      <td>24</td>\n",
       "      <td>16.70</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Bloomingdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-01 00:41:29</td>\n",
       "      <td>41</td>\n",
       "      <td>10.70</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Central Harlem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-01 00:50:32</td>\n",
       "      <td>24</td>\n",
       "      <td>32.95</td>\n",
       "      <td>Green</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Bloomingdale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime  PULocationID  total_amount Taxi_Color    Borough  \\\n",
       "0  2023-01-01 00:26:10           166         24.18      Green  Manhattan   \n",
       "1  2023-01-01 00:51:03            24         15.84      Green  Manhattan   \n",
       "2  2023-01-01 00:35:12           223         11.64      Green     Queens   \n",
       "3  2023-01-01 00:13:14            41         10.20      Green  Manhattan   \n",
       "4  2023-01-01 00:33:04            41          8.00      Green  Manhattan   \n",
       "5  2023-01-01 00:53:31            41         22.95      Green  Manhattan   \n",
       "6  2023-01-01 00:09:14           181         29.20      Green   Brooklyn   \n",
       "7  2023-01-01 00:11:58            24         16.70      Green  Manhattan   \n",
       "8  2023-01-01 00:41:29            41         10.70      Green  Manhattan   \n",
       "9  2023-01-01 00:50:32            24         32.95      Green  Manhattan   \n",
       "\n",
       "                  Zone  \n",
       "0  Morningside Heights  \n",
       "1         Bloomingdale  \n",
       "2             Steinway  \n",
       "3       Central Harlem  \n",
       "4       Central Harlem  \n",
       "5       Central Harlem  \n",
       "6           Park Slope  \n",
       "7         Bloomingdale  \n",
       "8       Central Harlem  \n",
       "9         Bloomingdale  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df], ignore_index=True)\n",
    "final_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
